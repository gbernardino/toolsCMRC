{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Database parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas, numpy as np\n",
    "import parsingDatabaseUtils, re\n",
    "import xml, itertools, collections, xml.etree.ElementTree as ET\n",
    "import tqdm, importlib, dateparser, dateparser.search\n",
    "import parseMeasurementsByDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "casos = pandas.read_csv('Venezolanas2/casos.csv', index_col = 0)\n",
    "pacientes = pandas.read_csv('Venezolanas2/pacientes.csv', index_col = 0)\n",
    "pacientes.index = pacientes.index.map(str)\n",
    "\n",
    "registros = pandas.read_csv('Venezolanas2/registros.csv', index_col = 0)\n",
    "registros.index = registros.index.map(str)\n",
    "\n",
    "#diagnosis = pandas.read_csv('Venezolanas2/diagnosis.csv', index_col = 0)\n",
    "procedimientos = pandas.read_csv('Venezolanas2/procedimientos.csv', index_col = 0)\n",
    "procedimientos.index = procedimientos.index.map(str)\n",
    "\n",
    "procedimientosDesc = pandas.read_csv('Venezolanas2/procedimientosID.csv', index_col = 0)\n",
    "registrosByCaso = registros.groupby('Caso')\n",
    "\n",
    "entriesInfirmery = pandas.read_csv('Venezolanas2/enfermeriaMedidas.csv', index_col = 0)\n",
    "entriesInfirmeryByCase = entriesInfirmery.groupby('IdAdmision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "classificationProcedures = {'H2968': 'o', 'H2123' : 'o', 'H0165': 'o', 'H0193': 'o', 'H2120': 'o', 'H2379': 'o', 'H2383': 'o', 'H2386': 'o', 'H2407': 'o', 'H2415': 'o', 'H2595': 'o', 'H2684': 'o', 'H2849': 'o', 'H2852': 'o', 'H2880': 'o', 'H2882': 'o', 'H2884': 'o', 'H2892': 'o', 'H2901': 'o', 'H2904': 'o', 'H2910': 'o', 'H2916': 'o', 'H2959': 'o', 'H2963': 'o', 'H2974': 'a', 'H2975': 'a', 'H3038': 'o', 'H3065': 'o', 'H3066': 'o', 'H3078': 'o', 'H3089': 'p', 'H3092': 'p', 'H3094': 'p', 'H3099': 'a', 'H3100': 'a', 'H3108': 'o', 'H3109': 'o', 'H3111': 'o', 'H3114': 'o', 'H3118': 'o', 'H4421': 'o', 'H4494': 'o', 'H4496': 'o', 'HE020': 'o'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Select a case\n",
    "Identify all  cases with an associated procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Identify all  cases with an associated procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "interventionToCase = {}\n",
    "caseToProcedureBirths = {}\n",
    "checkSeveralProcedures = []\n",
    "for i,r  in tqdm.tqdm_notebook(registros.iterrows()):\n",
    "    if isinstance(r.RegistroXML, str) and '<row NombreCampo=\"IdDescripcion\"' in r.RegistroXML:\n",
    "        et = ET.fromstring(r.RegistroXML)\n",
    "        idDescripcionProcedimiento = et.find('.//row[@NombreCampo=\"IdDescripcion\"]').get('ValorCampo')\n",
    "        interventionToCase[idDescripcionProcedimiento] = (r.Caso, r.NumeroHistoria, i)\n",
    "        procedureType = re.findall('<idProcedimiento>([a-zA-Z0-9]*)</idProcedimiento>', procedimientos.loc[idDescripcionProcedimiento].XmlDescripcion)[0]\n",
    "        if classificationProcedures[procedureType] == 'p':\n",
    "            \n",
    "            #If it is the case that they need to stop labour because a c-section is needed\n",
    "            if '<postDiagnosticoPrincipal>O821 - PARTO POR CESAREA DE EMERGENCIA</postDiagnosticoPrincipal>' in \\\n",
    "                procedimientos.loc[idDescripcionProcedimiento].XmlDescripcion:\n",
    "                continue\n",
    "                \n",
    "            elif r.Caso in caseToProcedureBirths:\n",
    "                r1 = caseToProcedureBirths[r.Caso]\n",
    "                r2 =procedimientos.loc[idDescripcionProcedimiento]\n",
    "                if r1.XmlDescripcion == r2.XmlDescripcion:\n",
    "                    continue\n",
    "                else:\n",
    "                    checkSeveralProcedures.append(r.Caso)\n",
    "                    print('error', r.Caso)\n",
    "                    if r1.FechaRegistro > r2.FechaRegistro:\n",
    "                        caseToProcedureBirths[r.Caso] = procedimientos.loc[idDescripcionProcedimiento]\n",
    "            else:\n",
    "                caseToProcedureBirths[r.Caso] = procedimientos.loc[idDescripcionProcedimiento]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import birthDatasetStructure\n",
    "importlib.reload(birthDatasetStructure)\n",
    "# Split in newborn\n",
    "registrosByCaso = registros.groupby('Caso')\n",
    "processedDatasets = {}\n",
    "for c, p in tqdm.tqdm_notebook(caseToProcedureBirths.items()):\n",
    "    if c not in casos.index:\n",
    "        print('ERROR!', c)\n",
    "        continue\n",
    "        \n",
    "    if c in entriesInfirmeryByCase.groups:\n",
    "        entriesInf = entriesInfirmeryByCase.get_group(c)\n",
    "    else:\n",
    "        entriesInf = pandas.DataFrame()\n",
    "    processedDatasets[c] = birthDatasetStructure.BirthDataset(c, casos.loc[c], p, registrosByCaso.get_group(c), \n",
    "                                                              pacientes,entriesInf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#Look for twins\n",
    "for c, p in processedDatasets.items():\n",
    "    \n",
    "    if len(p.registrosRecienNacido) > 1:\n",
    "        print(c, p.procTypeId,  len(p.registrosRecienNacido))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinDicts(d1, d2):\n",
    "    d2 = d2.copy()\n",
    "    for k in d1:\n",
    "        if k in d2 and d1[k] != d2[k]:\n",
    "            d2['error_key_%s' % str(k)] = True\n",
    "    d2.update(d1)\n",
    "    return d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "importlib.reload(parsingDatabaseUtils)\n",
    "resSIP = {}\n",
    "breakLoop = False\n",
    "count = 0\n",
    "for c, p in tqdm.tqdm_notebook(processedDatasets.items()):\n",
    "    resSIP[c] = parsingDatabaseUtils.getMotherData(p)\n",
    "    resSIP[c] = joinDicts(resSIP[c], parsingDatabaseUtils.getInformationFromProcedureDescription(p))\n",
    "    for k in p.registrosRecienNacido:\n",
    "        resSIP[c] = joinDicts(resSIP[c], parsingDatabaseUtils.getNewbornData(p, k))\n",
    "df = pandas.DataFrame.from_dict(resSIP, orient = 'index')\n",
    "#l = list(df[(df.VAR_0294 != df.VAR_0294) & (df.VAR_0293 != df.VAR_0293)].index)\n",
    "#print(len(l))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parseMeasurementsByDay\n",
    "importlib.reload(parseMeasurementsByDay)\n",
    "measurements = {}\n",
    "measurementsControlsPrenatal = {}\n",
    "for c, p in tqdm.tqdm_notebook(processedDatasets.items()):\n",
    "    measurements[c] = parseMeasurementsByDay.getParaClinicsHospitalisation(p) + parseMeasurementsByDay.getAllVitalSigns(p)\n",
    "    if p.epicrisis is not None:\n",
    "        measurementsControlsPrenatal[c] = parseMeasurementsByDay.parseParaclinicsBeforeHospitalisation(p.epicrisis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMeasurements.groupby('Campo')['Valor'].agg(['median', 'max', 'min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, p in tqdm.tqdm_notebook(processedDatasets.items()):\n",
    "    res = {}\n",
    "    dfMeasurements = pandas.DataFrame(data = measurements[c], columns =['Campo', 'Fecha', 'Valor'])\n",
    "    dfMeasurements.Valor = dfMeasurements.Valor.map(lambda s: s.replace(',', '.') if isinstance(s, str) else s)\n",
    "    dfMeasurements.Valor = dfMeasurements.Valor.astype(float)\n",
    "    dfValues =dfMeasurements.groupby('Campo')['Valor'].agg(['median', 'max', 'min'])\n",
    "    for var, row in dfValues.iterrows():\n",
    "        res[var + '_median'] = row.median()\n",
    "        res[var + '_max'] = row.max()\n",
    "        res[var + '_min'] = row.min()\n",
    "    resSIP[c].update(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dfResSIP = pandas.DataFrame.from_dict(resSIP, orient = 'index')\n",
    "dfResSIP.to_csv('resultsSIP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for c,  _ in df[df['sufrimientoFetal'] == 'SI'].iterrows():\n",
    "    et = ET.fromstring(processedDatasets[c].epicrisis.RegistroXML)\n",
    "    print(parsingDatabaseUtils.findInXML('MedicamentosAdministrado', et ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df[df['VAR_0425'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for _, p in processedDatasets['AD218865'].registrosRecienNacido['796790'].items():\n",
    "    parsingDatabaseUtils.prettyPrintXML(p.RegistroXML)\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "len(df.loc[df['VAR_0314'] != df['VAR_0314']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "errorCount = 0\n",
    "for c,v in resSIP.items():\n",
    "    if len(v) == 0:\n",
    "        errorCount += 1\n",
    "print(errorCount)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "def f(c):\n",
    "    parsingDatabaseUtils.prettyPrintXML(processedDatasets[c].procedure.XmlDescripcion)\n",
    "interact(lambda i: f(l[i]), i = (0, len(l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "noEpicrsis = []\n",
    "noIngreso = []\n",
    "\n",
    "noDischarge = []\n",
    "for c, p in processedDatasets.items():\n",
    "    if p.epicrisis is None:\n",
    "        noDischarge.append(c)\n",
    "    if p.ingreso is None:\n",
    "        noIngreso.append(c)\n",
    "print('no emergency' , len(noIngreso), 'no epi', len(noDischarge), len(processedDatasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "c = noIngreso[10]\n",
    "registrosByCaso.get_group(c)\n",
    "#parsingDatabaseUtils.prettyPrintXML(registros.loc['1025813', 'RegistroXML'])\n",
    "#casos.loc[casos.Paciente == 184931 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for c, p in processedDatasets.items():\n",
    "    if p.epicrisis is None:\n",
    "        continue\n",
    "    et = ET.fromstring(p.epicrisis.RegistroXML)\n",
    "    ant = parsingDatabaseUtils.fullCleanTxt(parsingDatabaseUtils.findInXML('AntecedentesHTML', et))\n",
    "    if not 'paracli' in ant:\n",
    "        count += 1\n",
    "    else:\n",
    "        print(ant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "c = 'AD284225'\n",
    "k = next(iter(processedDatasets[c].registrosRecienNacido.keys()))\n",
    "parsingDatabaseUtils.prettyPrintXML(processedDatasets[c].registrosRecienNacido[k][k].RegistroXML)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "c = list(processedDatasets.keys())[884]\n",
    "count = 0\n",
    "for c in processedDatasets.keys():\n",
    "    try:\n",
    "        if 'ECLAMPS' in processedDatasets[c].epicrisis.RegistroXML:\n",
    "            count += 1\n",
    "            #parsingDatabaseUtils.prettyPrintXML(processedDatasets[c].epicrisis.RegistroXML)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "c = list(processedDatasets.keys())[244]\n",
    "parsingDatabaseUtils.prettyPrintXML(processedDatasets[c].epicrisis.RegistroXML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# read paraclinics. Assume that the date is just bmonthre them, or in the same line\n",
    "\n",
    "pos = ['pos', '\\+', 'reac']\n",
    "neg = ['neg', '-', 'no']\n",
    "vih1  = 'vih\\s*[1i]'\n",
    "vih2 = 'vih\\s*(:?2|ii)'\n",
    "vih12 = 'vih\\s*[1i]\\s*(:?2|ii)'\n",
    "prt = '(:?PRUEBA RAPIDA TREPONEMICA|PRT)'\n",
    "vdrl = '(:?VDRL|SIF[A-Z]*|RPR|FTA|FTA ABS)'\n",
    "floatParse = '[0-9]*[\\.,]?[0-9]+'\n",
    "\n",
    "hematology = {\n",
    "'HCT' : '(HCT|HTO|HTC|HEMATO[A-Z]*)',\n",
    "'HB' : '(HB|HEMOGLOB[A-Z]*)',\n",
    "'LEU' : '(LEU[A-Z]*)',\n",
    "'NEU' : '(NEU[A-Z]*)',\n",
    "'LIN' : '(LIN)',\n",
    "'MONO' : '(MONO[A-Z]*)',\n",
    "'PLAQ' : '(PL[A-Z]*|PQT)'}\n",
    "\n",
    "meses = ['ENERO', 'FEBRERO', 'MARZO', 'ABRIL', 'MAYO', 'JUNIO', 'JULIO', 'AGOSTO', 'SEPTIEMBRE', 'OCTUBRE', 'NOVIEMBRE', 'DICIEMBRE']\n",
    "meses = meses + list(map(lambda s: s[:3], meses))\n",
    "sep= '\\s*[,;:]?\\s*'\n",
    "separadorFecha = '(?:[\\.\\\\/-]|DE|DEL|\\s)'\n",
    "date =  ' \\(?' +  '((?:[0-9]|[0-3][0-9])'+ sep + separadorFecha + sep + '(?:[0-9]+|%s)'%  '|'.join(meses) + \\\n",
    "                       sep + separadorFecha + sep + '(?:[0-9]+))' + '\\)?' \n",
    "\n",
    "def parseParaclinics(r, lastDate = None):\n",
    "    \n",
    "    if not isinstance(r, str):\n",
    "        rET = ET.fromstring(r.RegistroXML)\n",
    "        rTxt = parsingDatabaseUtils.fullCleanTxt(parsingDatabaseUtils.findInXML('AntecedentesHTML', rET))\n",
    "        rTxt = parsingDatabaseUtils.removeWords(rTxt, ['de', 'y', 'a', 'el', 'los'])\n",
    "    else:\n",
    "        rTxt = r\n",
    "        \n",
    "        \n",
    "    lastDate = None\n",
    "    results = collections.defaultdict(dict)\n",
    "    results['text'] = rTxt\n",
    "    if re.findall('(no|sin|ni) (prese[a-z]*|tien[a-z]*|tra[a-z]*)(\\s)*para', rTxt):\n",
    "        results['sinParaclinicos'] = True\n",
    "        return results\n",
    "    \n",
    "    for i, l in enumerate(rTxt.splitlines()):\n",
    "        l = ' ' + l\n",
    "        # use instead dateparser.search.search_dates  <- it goes too slow\n",
    "        d = re.findall(date, l, re.IGNORECASE)\n",
    "        # dFiltered = [dateparser.parse(dd) for dd in d]\n",
    "        #dFiltered = [dd for dd in dFiltered if dd]\n",
    "\n",
    "        if len(d) == 1.:\n",
    "            dateParsed = parsingDatabaseUtils.parseDate(d[0])\n",
    "            if dateParsed:\n",
    "                #lastDate ='%02d/%02d/%d' %(dateParsed.day, dateParsed.month, dateParsed.year)\n",
    "                lastDate = '/'.join(dateParsed)\n",
    "        elif len(d):\n",
    "            lastDate = None\n",
    "            \n",
    "            \n",
    "        if len(d) <= 1 and lastDate:\n",
    "            #Hematology\n",
    "            for p, v in hematology.items():\n",
    "                hematologyRes = re.findall('%s (%s)[^x]' % (v, floatParse), l, re.IGNORECASE)\n",
    "                if hematologyRes:\n",
    "                    results[lastDate][p] = hematologyRes[0][1]\n",
    "\n",
    "            #sifilis\n",
    "            sif1 = ' ' + vdrl + \" (%s)\" % '|'.join(pos + neg)\n",
    "            searchSif1 = re.findall(sif1, l, re.IGNORECASE)\n",
    "            sif2 = ' ' + prt + \" (%s)\" % '|'.join(pos + neg)    \n",
    "            searchSif2 = re.findall(sif2, l, re.IGNORECASE)\n",
    "            if searchSif1:\n",
    "                results[lastDate]['vdrl'] =searchSif1[0][1] in pos\n",
    "            if searchSif2:\n",
    "                results[lastDate]['prt'] =searchSif2[0][1] in pos\n",
    "            # TODO: vih\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def paraclinicsToDF(p):\n",
    "    res = {}\n",
    "    res['noParaclinicalTestsConfirmed'] = 'sinParaclinicos' in p\n",
    "    i = 0\n",
    "    for date in sorted(p.keys()):\n",
    "        if date  in ['sinParaclinicos', 'text']: \n",
    "            continue\n",
    "        res['day_%d' % i] = date\n",
    "        for k, v in p[date].items():\n",
    "            res['day_%d' % i + k] = v \n",
    "        i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "paraClinics = {}\n",
    "for c, p in tqdm.tqdm_notebook(processedDatasets.items()):\n",
    "    if p.epicrisis is None:\n",
    "        continue\n",
    "    d =parseParaclinics(p.epicrisis)\n",
    "    paraClinics[c] = paraclinicsToDF(parseParaclinics(p.epicrisis))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dfParaClinics.noParaclinicalTestsConfirmed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dfParaClinics = pandas.DataFrame.from_dict(paraClinics, orient = 'index')\n",
    "dfParaClinics = dfParaClinics[sorted(dfParaClinics.columns)]\n",
    "dfParaClinics.to_csv('paraclinics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for c, p in paraClinics.items():\n",
    "    if len(p) != 1:\n",
    "        print(paraClinics[c]['text'])\n",
    "        print('-----------------')\n",
    "        for k in p:\n",
    "            if k != 'text':\n",
    "                print(k, p[k])\n",
    "        print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def merge2DF(df1, df2):\n",
    "    \"\"\"\n",
    "    Returns the merge of 2 df with the same index (1 to 1)\n",
    "    In case of columns with the same name, check if the values are the same (or one of them is NA)\n",
    "    Creates new error column to see where there has been problems\n",
    "    \"\"\"\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
